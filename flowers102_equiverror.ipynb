{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/yegonkim/.conda/envs/brad/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import os\n",
    "import math\n",
    "from color.CEConv.models.resnet_variational import ResNet18 as ResNet18_partial\n",
    "from color.generate_data import generate_102flower_data\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.rc('axes', labelsize=15)   # x,y축 label 폰트 크기\n",
    "plt.rc('xtick', labelsize=15)\n",
    "plt.rc('ytick', labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'color', 'dataset': 'Flowers102', 'pretrained': None, 'device': 'cuda', 'seed': 2024, 'comment': '', 'no_workers': 1, 'flops': False, 'train': {'do': True, 'epochs': 700, 'batch_size': 64, 'valid_every': 10, 'weight_decay': 0.01, 'lr': 0.0002, 'lr_probs': 2e-05, 'lamda': 0.1, 'lamda2': 0.01}, 'model': {'architecture': 'resnet18', 'rot': 3, 'partial': False, 'variational': True, 'version': 'v1.2', 'maxpool': False, 'insta': False, 'insta_params': {'num_samples': 1, 'lambda_entropy': 0.0001, 'h_min': -1.5, 'h_max': 2}}, 'wandb': {'entity': 'kim-hyunsu', 'project': 'partial_equiv', 'mode': 'online'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kim-hyunsu/partial_equiv/runs/0jfaj1h7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f090c41cb80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run_path = \"kim-hyunsu/partial_equiv/0vh427nx\"\n",
    "file = \"/mnt/home/yegonkim/home/partial_equiv_project/partial_equiv/wandb/run-20240324_193430-1ca72q92/files/config.yaml\"\n",
    "with open(file) as f:\n",
    "    used_args = yaml.safe_load(f)\n",
    "args = dict()\n",
    "for k in used_args:\n",
    "    v = used_args[k]\n",
    "    if isinstance(v, dict) and not k.startswith(\"_\"):\n",
    "        if \".\" in k:\n",
    "            temp = args\n",
    "            for _k in k.split(\".\")[:-1]:\n",
    "                if temp.get(_k) is None:\n",
    "                    temp[_k] = dict()\n",
    "                temp = temp[_k]\n",
    "            temp[k.split(\".\")[-1]] = v[\"value\"]\n",
    "        else:\n",
    "            args[k] = v[\"value\"]\n",
    "args = EasyDict(args)\n",
    "print(args)\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
    "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
    "\n",
    "wandb.init(\n",
    "    project=\"partial_equiv\",\n",
    "    entity=\"kim-hyunsu\",\n",
    "    reinit=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_names = ['pink primrose'\n",
    ",'hard-leaved pocket orchid'\n",
    ",'canterbury bells'\n",
    ",'sweet pea'\n",
    ",'english marigold'\n",
    ",'tiger lily'\n",
    ",'moon orchid'\n",
    ",'bird of paradise'\n",
    ",'monkshood'\n",
    ",'globe thistle'\n",
    ",'snapdragon'\n",
    ",\"colt's foot\"\n",
    ",'king protea'\n",
    ",'spear thistle'\n",
    ",'yellow iris'\n",
    ",'globe-flower'\n",
    ",'purple coneflower'\n",
    ",'peruvian lily'\n",
    ",'balloon flower'\n",
    ",'giant white arum lily'\n",
    ",'fire lily'\n",
    ",'pincushion flower'\n",
    ",'fritillary'\n",
    ",'red ginger'\n",
    ",'grape hyacinth'\n",
    ",'corn poppy'\n",
    ",'prince of wales feathers'\n",
    ",'stemless gentian'\n",
    ",'artichoke'\n",
    ",'sweet william'\n",
    ",'carnation'\n",
    ",'garden phlox'\n",
    ",'love in the mist'\n",
    ",'mexican aster'\n",
    ",'alpine sea holly'\n",
    ",'ruby-lipped cattleya'\n",
    ",'cape flower'\n",
    ",'great masterwort'\n",
    ",'siam tulip'\n",
    ",'lenten rose'\n",
    ",'barbeton daisy'\n",
    ",'daffodil'\n",
    ",'sword lily'\n",
    ",'poinsettia'\n",
    ",'bolero deep blue'\n",
    ",'wallflower'\n",
    ",'marigold'\n",
    ",'buttercup'\n",
    ",'oxeye daisy'\n",
    ",'common dandelion'\n",
    ",'petunia'\n",
    ",'wild pansy'\n",
    ",'primula'\n",
    ",'sunflower'\n",
    ",'pelargonium'\n",
    ",'bishop of llandaff'\n",
    ",'gaura'\n",
    ",'geranium'\n",
    ",'orange dahlia'\n",
    ",'pink-yellow dahlia?'\n",
    ",'cautleya spicata'\n",
    ",'japanese anemone'\n",
    ",'black-eyed susan'\n",
    ",'silverbush'\n",
    ",'californian poppy'\n",
    ",'osteospermum'\n",
    ",'spring crocus'\n",
    ",'bearded iris'\n",
    ",'windflower'\n",
    ",'tree poppy'\n",
    ",'gazania'\n",
    ",'azalea'\n",
    ",'water lily'\n",
    ",'rose'\n",
    ",'thorn apple'\n",
    ",'morning glory'\n",
    ",'passion flower'\n",
    ",'lotus'\n",
    ",'toad lily'\n",
    ",'anthurium'\n",
    ",'frangipani'\n",
    ",'clematis'\n",
    ",'hibiscus'\n",
    ",'columbine'\n",
    ",'desert-rose'\n",
    ",'tree mallow'\n",
    ",'magnolia'\n",
    ",'cyclamen '\n",
    ",'watercress'\n",
    ",'canna lily'\n",
    ",'hippeastrum '\n",
    ",'bee balm'\n",
    ",'ball moss'\n",
    ",'foxglove'\n",
    ",'bougainvillea'\n",
    ",'camellia'\n",
    ",'mallow'\n",
    ",'mexican petunia'\n",
    ",'bromelia'\n",
    ",'blanket flower'\n",
    ",'trumpet creeper'\n",
    ",'blackberry lily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get samples from test dataset\n",
    "dataset = generate_102flower_data(size=224)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        dataset[\"test\"],\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (maxpool): GroupMaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (conv1): CEConv2d(\n",
       "      3, 55, kernel_size=(7, 7), stride=(2, 2), padding=(1, 1), bias=False\n",
       "      (filter_conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (filter_nonlinear): ReLU()\n",
       "      (filter_conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (filter_linear1): Linear(in_features=6, out_features=1, bias=True)\n",
       "    )\n",
       "    (bn1): BatchNorm3d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (bn1): BatchNorm3d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (bn2): BatchNorm3d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "          (conv1): CEConv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (conv2): CEConv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (bn1): BatchNorm3d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (bn2): BatchNorm3d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "          (conv1): CEConv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (conv2): CEConv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (bn1): BatchNorm3d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (bn2): BatchNorm3d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential(\n",
       "            (0): CEConv2d(55, 110, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm3d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv1): CEConv2d(55, 110, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (conv2): CEConv2d(110, 110, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (bn1): BatchNorm3d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (bn2): BatchNorm3d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "          (conv1): CEConv2d(110, 110, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (conv2): CEConv2d(110, 110, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (bn1): BatchNorm3d(221, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (bn2): BatchNorm3d(221, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential(\n",
       "            (0): CEConv2d(110, 221, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm3d(221, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv1): CEConv2d(110, 221, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (conv2): CEConv2d(221, 221, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (bn1): BatchNorm3d(221, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (bn2): BatchNorm3d(221, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "          (conv1): CEConv2d(221, 221, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (conv2): CEConv2d(221, 221, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): VarBasicBlock(\n",
       "          (bn1): BatchNorm3d(443, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (bn2): BatchNorm3d(443, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential(\n",
       "            (0): CEConv2d(\n",
       "              221, 443, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "              (filter_conv1): Conv1d(221, 221, kernel_size=(2,), stride=(1,))\n",
       "              (filter_nonlinear): ReLU()\n",
       "              (filter_conv2): Conv1d(221, 221, kernel_size=(2,), stride=(1,))\n",
       "              (filter_linear1): Linear(in_features=221, out_features=1, bias=True)\n",
       "            )\n",
       "            (1): BatchNorm3d(443, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv1): CEConv2d(\n",
       "            221, 443, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "            (filter_conv1): Conv1d(221, 221, kernel_size=(2,), stride=(1,))\n",
       "            (filter_nonlinear): ReLU()\n",
       "            (filter_conv2): Conv1d(221, 221, kernel_size=(2,), stride=(1,))\n",
       "            (filter_linear1): Linear(in_features=221, out_features=1, bias=True)\n",
       "          )\n",
       "          (conv2): CEConv2d(\n",
       "            443, 443, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (filter_conv1): Conv1d(443, 443, kernel_size=(2,), stride=(1,))\n",
       "            (filter_nonlinear): ReLU()\n",
       "            (filter_conv2): Conv1d(443, 443, kernel_size=(2,), stride=(1,))\n",
       "            (filter_linear1): Linear(in_features=443, out_features=1, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (1): VarBasicBlock(\n",
       "          (bn1): BatchNorm3d(443, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (bn2): BatchNorm3d(443, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (shortcut): Sequential()\n",
       "          (conv1): CEConv2d(\n",
       "            443, 443, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (filter_conv1): Conv1d(443, 443, kernel_size=(2,), stride=(1,))\n",
       "            (filter_nonlinear): ReLU()\n",
       "            (filter_conv2): Conv1d(443, 443, kernel_size=(2,), stride=(1,))\n",
       "            (filter_linear1): Linear(in_features=443, out_features=1, bias=True)\n",
       "          )\n",
       "          (conv2): CEConv2d(\n",
       "            443, 443, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "            (filter_conv1): Conv1d(443, 443, kernel_size=(2,), stride=(1,))\n",
       "            (filter_nonlinear): ReLU()\n",
       "            (filter_conv2): Conv1d(443, 443, kernel_size=(2,), stride=(1,))\n",
       "            (filter_linear1): Linear(in_features=443, out_features=1, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (linear): Linear(in_features=443, out_features=102, bias=True)\n",
       "    (cosetpoollayer): GroupCosetMaxPool()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gumbel_no_iterations = math.ceil(len(dataset[\"train\"]) / float(args.train.batch_size))  # Iter per epoch\n",
    "gumbel_no_iterations = args.train.epochs * gumbel_no_iterations\n",
    "model = ResNet18_partial(pretrained=False, progress=False, rotations=args.model.rot, num_classes=102,\n",
    "                groupcosetmaxpool=True, separable=True,\n",
    "                gumbel_no_iterations=gumbel_no_iterations,\n",
    "                version=args.model.version\n",
    "        ).to(args.device)\n",
    "# load checkpoint\n",
    "# model_checkpoint = wandb.restore('checkpoint.pt', run_path)\n",
    "# model.load_state_dict(\n",
    "#             torch.load(model_checkpoint.name, map_location=args.device)[\"model\"],\n",
    "#             strict=True,\n",
    "#         )\n",
    "model = torch.nn.DataParallel(model)\n",
    "checkpoint_path = \"/mnt/home/yegonkim/home/partial_equiv_project/partial_equiv/wandb/run-20240324_193430-1ca72q92/files/checkpoint.pt\"\n",
    "model.load_state_dict(\n",
    "            torch.load(checkpoint_path, map_location=args.device)[\"model\"],\n",
    "            strict=True,\n",
    "        )\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equiv_error(a, b):\n",
    "    diff = torch.norm(a-b, dim=-1)\n",
    "    anorm = torch.norm(a, dim=-1)\n",
    "    bnorm = torch.norm(b, dim=-1)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equiv_error(target_labels):\n",
    "    error_dict = dict()\n",
    "    for l in target_labels:\n",
    "        error_dict[str(l)] = []\n",
    "    jitterings = torch.arange(0,3)/3-0.5 \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            images = images.to(args.device)\n",
    "            labels = labels.to(args.device)\n",
    "            if labels[0] not in target_labels:\n",
    "                continue\n",
    "            outputs = model(images)[0]\n",
    "            pred = torch.argmax(outputs, dim=-1)\n",
    "            if torch.any(pred != labels):\n",
    "                continue\n",
    "            # outputs = torch.softmax(outputs, dim=-1)[labels[0]]\n",
    "            outputs = torch.softmax(outputs, dim=-1)\n",
    "            _error_list = []\n",
    "            for j in jitterings:\n",
    "                if j == 0:\n",
    "                    continue\n",
    "                outputs_T = model(TF.adjust_hue(images, j))[0]\n",
    "                # outputs_T = torch.softmax(outputs_T, dim=-1)[labels[0]]\n",
    "                outputs_T = torch.softmax(outputs_T, dim=-1)\n",
    "                error = equiv_error(outputs, outputs_T)\n",
    "                _error_list.append(error)\n",
    "            error = torch.stack(_error_list).mean()\n",
    "            assert len(error.shape) == 0\n",
    "            error_dict[str(labels[0])].append(error)\n",
    "    error_list = []\n",
    "    for l in target_labels:\n",
    "        stack = torch.stack(error_dict[str(l)])\n",
    "        # sorted, _ = torch.sort(stack, dim=0)\n",
    "        ratio = (stack < 0.6).sum() / len(stack)\n",
    "        error_list.append(ratio)\n",
    "    return error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6149 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6149/6149 [05:02<00:00, 20.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pink primrose: 1.0\n",
      "hard-leaved pocket orchid: 1.0\n",
      "canterbury bells: 1.0\n",
      "sweet pea: 1.0\n",
      "english marigold: 1.0\n",
      "tiger lily: 1.0\n",
      "moon orchid: 1.0\n",
      "bird of paradise: 1.0\n",
      "monkshood: 1.0\n",
      "globe thistle: 1.0\n",
      "snapdragon: 1.0\n",
      "colt's foot: 1.0\n",
      "king protea: 1.0\n",
      "spear thistle: 1.0\n",
      "yellow iris: 1.0\n",
      "globe-flower: 1.0\n",
      "purple coneflower: 1.0\n",
      "peruvian lily: 1.0\n",
      "balloon flower: 1.0\n",
      "giant white arum lily: 1.0\n",
      "fire lily: 1.0\n",
      "pincushion flower: 1.0\n",
      "fritillary: 0.9999999403953552\n",
      "red ginger: 1.0\n",
      "grape hyacinth: 1.0\n",
      "corn poppy: 1.0\n",
      "prince of wales feathers: 1.0\n",
      "stemless gentian: 1.0\n",
      "artichoke: 0.9999999403953552\n",
      "sweet william: 1.0\n",
      "carnation: 1.0\n",
      "garden phlox: 1.0\n",
      "love in the mist: 1.0\n",
      "mexican aster: 1.0\n",
      "alpine sea holly: 1.0\n",
      "ruby-lipped cattleya: 1.0\n",
      "cape flower: 1.0\n",
      "great masterwort: 1.0\n",
      "siam tulip: 1.0\n",
      "lenten rose: 1.0\n",
      "barbeton daisy: 1.0\n",
      "daffodil: 1.0\n",
      "sword lily: 1.0\n",
      "poinsettia: 1.0\n",
      "bolero deep blue: 1.0\n",
      "wallflower: 1.0\n",
      "marigold: 1.0\n",
      "buttercup: 1.0\n",
      "oxeye daisy: 1.0\n",
      "common dandelion: 1.0\n",
      "petunia: 1.0\n",
      "wild pansy: 1.0\n",
      "primula: 0.9999999403953552\n",
      "sunflower: 1.0\n",
      "pelargonium: 1.0\n",
      "bishop of llandaff: 1.0\n",
      "gaura: 1.0\n",
      "geranium: 1.0\n",
      "orange dahlia: 1.0\n",
      "pink-yellow dahlia?: 1.0\n",
      "cautleya spicata: 1.0\n",
      "japanese anemone: 1.0\n",
      "black-eyed susan: 1.0\n",
      "silverbush: 1.0\n",
      "californian poppy: 1.0\n",
      "osteospermum: 0.9999999403953552\n",
      "spring crocus: 1.0\n",
      "bearded iris: 1.0\n",
      "windflower: 1.0\n",
      "tree poppy: 1.0\n",
      "gazania: 1.0\n",
      "azalea: 1.0\n",
      "water lily: 1.0\n",
      "rose: 1.0\n",
      "thorn apple: 0.9999999403953552\n",
      "morning glory: 1.0\n",
      "passion flower: 1.0\n",
      "lotus: 1.0\n",
      "toad lily: 1.0\n",
      "anthurium: 1.0\n",
      "frangipani: 1.0\n",
      "clematis: 1.0\n",
      "hibiscus: 1.0\n",
      "columbine: 1.0\n",
      "desert-rose: 1.0\n",
      "tree mallow: 1.0\n",
      "magnolia: 1.0\n",
      "cyclamen : 1.0\n",
      "watercress: 1.0\n",
      "canna lily: 1.0\n",
      "hippeastrum : 1.0\n",
      "bee balm: 1.0\n",
      "ball moss: 1.0\n",
      "foxglove: 0.9999999403953552\n",
      "bougainvillea: 1.0\n",
      "camellia: 1.0\n",
      "mallow: 1.0\n",
      "mexican petunia: 1.0\n",
      "bromelia: 1.0\n",
      "blanket flower: 1.0\n",
      "trumpet creeper: 1.0\n",
      "blackberry lily: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_labels = torch.arange(102).to(args.device)\n",
    "error_list = get_equiv_error(target_labels)\n",
    "for l, e in zip(target_labels, error_list):\n",
    "    print(f\"{flower_names[l]}: {e}\")\n",
    "# plot_bar(target_labels, samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
