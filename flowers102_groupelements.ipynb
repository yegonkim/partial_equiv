{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/yegonkim/.conda/envs/brad/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import os\n",
    "import math\n",
    "from color.CEConv.models.resnet_variational import ResNet18 as ResNet18_partial\n",
    "\n",
    "from color.generate_data import generate_102flower_data\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.rc('axes', labelsize=15)   # x,y축 label 폰트 크기\n",
    "plt.rc('xtick', labelsize=15)\n",
    "plt.rc('ytick', labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'rot': 3, 'variational': True, 'version': 'v1.2', 'partial': False, 'insta': False, 'insta_params': {'num_samples': 1, 'lambda_entropy': 0.0001, 'h_min': -1.5, 'h_max': 2}}, 'seed': 2024, 'task': 'flowers', 'train': {'batch_size': 64, 'epochs': 700, 'lamda': 0.01, 'lamda2': 0.01, 'lr': 0.0002, 'lr_probs': 2e-05, 'valid_every': 10, 'weight_decay': 0.01, 'do': True}, 'wandb': {'entity': 'kim-hyunsu', 'mode': 'online', 'project': 'partial_equiv'}, 'type': 'color', 'dataset': 'Flowers102', 'pretrained': None, 'device': 'cuda', 'comment': '', 'no_workers': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ic31bck2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /mnt/home/yegonkim/home/partial_equiv_project/partial_equiv/wandb/offline-run-20240324_143033-ic31bck2<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240324_143033-ic31bck2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ic31bck2). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kim-hyunsu/partial_equiv/runs/a084g2qy?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4526d56f80>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_path = \"kim-hyunsu/partial_equiv/0vh427nx\"\n",
    "file = \"/mnt/home/yegonkim/home/partial_equiv_project/partial_equiv/wandb/run-20240323_060932-0vh427nx/files/config.yaml\"\n",
    "with open(file) as f:\n",
    "    used_args = yaml.safe_load(f)\n",
    "args = dict()\n",
    "for k in used_args:\n",
    "    v = used_args[k]\n",
    "    if isinstance(v, dict) and not k.startswith(\"_\"):\n",
    "        if \".\" in k:\n",
    "            temp = args\n",
    "            for _k in k.split(\".\")[:-1]:\n",
    "                if temp.get(_k) is None:\n",
    "                    temp[_k] = dict()\n",
    "                temp = temp[_k]\n",
    "            temp[k.split(\".\")[-1]] = v[\"value\"]\n",
    "        else:\n",
    "            args[k] = v[\"value\"]\n",
    "args = EasyDict(args)\n",
    "print(args)\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
    "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
    "\n",
    "wandb.init(\n",
    "    project=\"partial_equiv\",\n",
    "    entity=\"kim-hyunsu\",\n",
    "    reinit=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get samples from test dataset\n",
    "dataset = generate_102flower_data(size=224)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        dataset[\"test\"],\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gumbel_no_iterations = math.ceil(len(dataset[\"train\"]) / float(args.train.batch_size))  # Iter per epoch\n",
    "gumbel_no_iterations = args.train.epochs * gumbel_no_iterations\n",
    "model = ResNet18_partial(pretrained=False, progress=False, rotations=args.model.rot, num_classes=102,\n",
    "                groupcosetmaxpool=True, separable=True,\n",
    "                gumbel_no_iterations=gumbel_no_iterations,\n",
    "                version=args.model.version\n",
    "        ).to(args.device)\n",
    "# load checkpoint\n",
    "# model_checkpoint = wandb.restore('checkpoint.pt', run_path)\n",
    "# model.load_state_dict(\n",
    "#             torch.load(model_checkpoint.name, map_location=args.device)[\"model\"],\n",
    "#             strict=True,\n",
    "#         )\n",
    "model = torch.nn.DataParallel(model)\n",
    "checkpoint_path = \"/mnt/home/yegonkim/home/partial_equiv_project/partial_equiv/wandb/run-20240323_060932-0vh427nx/files/checkpoint.pt\"\n",
    "model.load_state_dict(\n",
    "            torch.load(checkpoint_path, map_location=args.device)[\"model\"],\n",
    "            strict=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_elements(target_labels, count):\n",
    "    samples = []\n",
    "    for target in target_labels:\n",
    "        count = 9\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(test_loader):\n",
    "                images = images.to(args.device)\n",
    "                labels = labels.to(args.device)\n",
    "                outputs = model(images)\n",
    "                prob_class = torch.softmax(outputs, dim=-1)[0,labels[0]]\n",
    "                if prob_class < 0.01:\n",
    "                    continue\n",
    "                if torch.any(labels==target) and count > 0:\n",
    "                    count -= 1\n",
    "                    continue\n",
    "                if torch.any(labels==target) and count == 0:\n",
    "                    images = images[labels==target]\n",
    "                    model(images)\n",
    "                    probs = None\n",
    "                    module = None\n",
    "                    for m in model.modules():\n",
    "                        if getattr(m, \"entropy\", None) is None:\n",
    "                            continue\n",
    "                        probs = m.probs_all\n",
    "                        module = m\n",
    "                    assert len(probs.shape) == 2\n",
    "                    prob_rotations = torch.arange(0,module.out_rotations).to(probs).view(1,-1)\n",
    "                    prob_rotations = torch.softmax(prob_rotations/probs,dim=-1)\n",
    "                    sample_rotation = (prob_rotations > (1/(module.out_rotations+1))).float()\n",
    "                    samples.append(sample_rotation.sum(-1).squeeze().detach().cpu())\n",
    "                    break\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(jitterings, predictions):\n",
    "    plt.figure(dpi=300)\n",
    "\n",
    "    plt.bar(jitterings, predictions, width=0.08, color=\"C1\")\n",
    "\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.ylabel('Confidence for Corresponding Class')\n",
    "    plt.xlabel('Hue Shift')\n",
    "    plt.xticks(jitterings)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'images/group_elements_bar.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/6149 [00:02<26:38,  3.84it/s]  \n",
      "  0%|          | 29/6149 [00:01<04:04, 25.03it/s]\n",
      "  1%|          | 71/6149 [00:01<02:43, 37.11it/s]\n",
      "  1%|▏         | 90/6149 [00:02<02:33, 39.53it/s]\n",
      "  2%|▏         | 125/6149 [00:02<02:15, 44.30it/s]\n",
      "  3%|▎         | 170/6149 [00:03<02:09, 46.11it/s]\n",
      "100%|██████████| 6149/6149 [01:50<00:00, 55.88it/s]\n",
      "  4%|▎         | 216/6149 [00:04<02:00, 49.41it/s]\n",
      "  5%|▍         | 282/6149 [00:05<01:58, 49.56it/s]\n",
      "100%|██████████| 6149/6149 [01:44<00:00, 58.70it/s]\n",
      "  5%|▌         | 336/6149 [00:06<01:47, 54.18it/s]\n",
      "100%|██████████| 6149/6149 [01:44<00:00, 59.03it/s]\n",
      "  8%|▊         | 465/6149 [00:08<01:43, 54.78it/s]\n",
      "  8%|▊         | 501/6149 [00:09<01:41, 55.56it/s]\n",
      "  8%|▊         | 522/6149 [00:09<01:41, 55.30it/s]\n",
      "100%|██████████| 6149/6149 [01:43<00:00, 59.27it/s]\n",
      " 10%|▉         | 592/6149 [00:10<01:41, 54.95it/s]\n",
      " 11%|█         | 657/6149 [00:11<01:37, 56.43it/s]\n",
      " 12%|█▏        | 720/6149 [00:12<01:36, 56.45it/s]\n",
      " 12%|█▏        | 758/6149 [00:13<01:35, 56.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(2.), tensor(2.), tensor(2.), tensor(2.), tensor(2.), tensor(2.), tensor(1.), tensor(2.), tensor(2.), tensor(2.), tensor(2.), tensor(2.), tensor(2.), tensor(2.), tensor(1.), tensor(2.)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_labels = torch.arange(20)\n",
    "samples = get_group_elements(target_labels, 0)\n",
    "print(samples)\n",
    "# plot_bar(target_labels, samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
